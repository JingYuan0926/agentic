import ollama from 'ollama';

async function testLLM() {
    try {
        console.log('ğŸ¤– Testing DeepSeek LLM...');
        const response = await ollama.chat({
            model: 'deepseek-r1:1.5b',
            messages: [{ 
                role: 'user', 
                content: 'What is food' 
            }]
        });

        console.log('\nâœ¨ DeepSeek response:', response.message.content);
        console.log('ğŸ“Š Response length:', response.message.content.length);
    } catch (error) {
        console.error('âŒ Error:', error);
    }
}

testLLM().catch(console.error); 